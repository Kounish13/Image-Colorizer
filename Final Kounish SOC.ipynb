{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e270d2-0073-4c1d-af51-cf1390808c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526daac7-d07e-4d41-b3c0-63cf7b360c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, Conv2DTranspose, Concatenate, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b260b036-53be-4b8c-bfd6-4d3e8fb26dac",
   "metadata": {},
   "source": [
    "[Kaggle Dataset Link](https://www.kaggle.com/datasets/arka47/movie-frames-24k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11596de7-4343-43a6-80d4-115579ae70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_size = 240\n",
    "subset_split = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b87d1e-2db8-4b82-8e3d-4d1d4aa1620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting image into LAB and extracting the dataset\n",
    "import zipfile\n",
    "zip_file_path = 'phto zip.zip'\n",
    "extract_folder_path = 'D:\\Image Classification\\Image\\photo extract'\n",
    "os.makedirs(extract_folder_path, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder_path)\n",
    "\n",
    "print(\"Extraction completed.\")\n",
    "\n",
    "do = r\"D:\\Image Classification\\Image\\photo extract\"\n",
    "x = []\n",
    "y = []\n",
    "for image_file in os.listdir( do )[ 0 : subset_split ]:\n",
    "    rgb_image = Image.open( os.path.join( do , image_file ) ).resize( ( img_size , img_size ) )\n",
    "    rgb_img_array = (np.asarray( rgb_image ) ) / 255\n",
    "    bw_image = rgb_image.convert( 'L' )\n",
    "    bw_img_array = ( np.asarray( bw_image ).reshape( ( img_size , img_size , 1 ) ) ) / 255\n",
    "    x.append( bw_img_array )\n",
    "    y.append( rgb_img_array )\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split( np.array(x) , np.array(y) , test_size=0.1 )\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices( ( train_x , train_y ) )\n",
    "dataset = dataset.batch( batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc07ac0-e1d9-41fc-89e2-dd228f3fa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building generator model\n",
    "def build_sequential_generator_model(input_shape=(img_size, img_size, 1)):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Bottleneck\n",
    "    model.add(layers.Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Conv2D(3, (1, 1), padding='same'))\n",
    "    model.add(layers.Activation('tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337bae6-3b13-4f7a-9323-7992a8eb8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building discriminator model\n",
    "def build_sequential_discriminator_model(input_shape=(256, 256, 3)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed658fa4-3449-403f-abf0-9dbbdba61e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output , real_y):\n",
    "    real_y = tf.cast( real_y , 'float32' )\n",
    "    return mse( fake_output , real_y )\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536a2db0-89bc-44f8-8929-709a0ff56dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d303222c-afb0-46cc-9db1-50eba8a3db60/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "generator = build_sequential_generator_model()\n",
    "discriminator = build_sequential_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f464116-1bba-4b14-b1ca-8ecbd55a3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step( input_x , real_y ):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator( input_x , training=True)\n",
    "        real_output = discriminator( real_y, training=True)\n",
    "        generated_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss( generated_images , real_y )\n",
    "        disc_loss = discriminator_loss( real_output, generated_output )\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a8247f-fad2-4f46-8ae4-f835d6397a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m( num_epochs ):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m( e )\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ( x , y ) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m( x\u001b[38;5;241m.\u001b[39mshape )\n\u001b[1;32m      8\u001b[0m         train_step( x , y )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 700\n",
    "\n",
    "for e in range( num_epochs ):\n",
    "    print( e )\n",
    "    for ( x , y ) in dataset:\n",
    "\n",
    "        print( x.shape )\n",
    "        train_step( x , y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be40650-8ba7-4658-84bf-fc508a3ee409",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y \u001b[38;5;241m=\u001b[39m generator( \u001b[43mtest_x\u001b[49m[\u001b[38;5;241m0\u001b[39m : ] )\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "y = generator( test_x[0 : ] ).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed982f5a-011b-47af-ae93-396b48b140f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_x\u001b[49m)):\n\u001b[1;32m      2\u001b[0m   plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      3\u001b[0m   or_image \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_x)):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  or_image = plt.subplot(3,3,1)\n",
    "  or_image.set_title('bw Input', fontsize=16)\n",
    "  plt.imshow( test_x[i].reshape((120,120)) , cmap='bw' )\n",
    "\n",
    "  in_image = plt.subplot(3,3,2)\n",
    "  image = Image.fromarray( ( y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
    "  image = np.asarray( image )\n",
    "  in_image.set_title('Colorized Output', fontsize=16)\n",
    "  plt.imshow( image )\n",
    "\n",
    "  ou_image = plt.subplot(3,3,3)\n",
    "  image = Image.fromarray( ( test_y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
    "  ou_image.set_title('Ground Truth', fontsize=16)\n",
    "  plt.imshow( image )\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19140ba2-5477-4cfb-a154-2ce7c4452c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
